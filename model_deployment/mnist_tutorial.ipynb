{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment for MNIST\n",
    "- Training Process\n",
    "    - DataSet Preparation\n",
    "    - Data Preprocessing\n",
    "    - Model Construction\n",
    "    - Traning\n",
    "    - Testing\n",
    "    - Model Saving & Loading\n",
    "- Deployment Process\n",
    "    - to ONNX\n",
    "    - Inference Engine\n",
    "        - ONNX Runtime\n",
    "        - TensorRT running"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "- MNIST\n",
    "- Preprocessing -> transforms.Compose()\n",
    "- DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    ")\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\n",
    "    root = './data', \n",
    "    train = True,\n",
    "    transform = data_tf,\n",
    "    download = True\n",
    ")\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train = False,\n",
    "    transform = data_tf\n",
    ")\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    print(img.size())\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "- N = (Width - Kernel_size + 2*Padding) / Stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model structure\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 1*1*28*28\n",
    "        self.convblock1 = ConvBlock(1, 32)\n",
    "        # 1*32*14*14\n",
    "        self.convblock2 = ConvBlock(32, 64)\n",
    "        # 1*64*7*7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = self.convblock1(img)\n",
    "        img = self.convblock2(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.fc1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.fc2(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1359, -0.0311, -0.0957,  0.0146,  0.1360, -0.0667,  0.0667, -0.1169,\n",
       "          0.0029, -0.1248]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trainset[0][0].view(1,1,28,28).cuda()\n",
    "model(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "- Loss\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.11541032046079636\n",
      "epoch: 1, loss: 0.0780627653002739\n",
      "epoch: 2, loss: 0.028133006766438484\n",
      "epoch: 3, loss: 0.08547574281692505\n",
      "epoch: 4, loss: 0.013079293072223663\n",
      "epoch: 5, loss: 0.015158281661570072\n",
      "epoch: 6, loss: 0.02131212316453457\n",
      "epoch: 7, loss: 0.03608933463692665\n",
      "epoch: 8, loss: 0.008750793524086475\n",
      "epoch: 9, loss: 0.0016039339825510979\n",
      "epoch: 10, loss: 0.0023217021953314543\n",
      "epoch: 11, loss: 0.0014150800416246057\n",
      "epoch: 12, loss: 0.028946593403816223\n",
      "epoch: 13, loss: 4.979946606908925e-05\n",
      "epoch: 14, loss: 5.748984676756663e-06\n",
      "epoch: 15, loss: 0.0003072724211961031\n",
      "epoch: 16, loss: 0.007224217057228088\n",
      "epoch: 17, loss: 0.0005629609222523868\n",
      "epoch: 18, loss: 0.0013020599726587534\n",
      "epoch: 19, loss: 0.002345251850783825\n",
      "epoch: 20, loss: 0.00010087257396662608\n",
      "epoch: 21, loss: 4.92084764118772e-05\n",
      "epoch: 22, loss: 0.0004791969258803874\n",
      "epoch: 23, loss: 1.950174555531703e-05\n",
      "epoch: 24, loss: 2.3306007278733887e-05\n",
      "epoch: 25, loss: 5.02959119330626e-05\n",
      "epoch: 26, loss: 0.00027265012613497674\n",
      "epoch: 27, loss: 1.1163329872942995e-05\n",
      "epoch: 28, loss: 7.39685638109222e-05\n",
      "epoch: 29, loss: 2.298345634699217e-06\n",
      "epoch: 30, loss: 1.6170866729225963e-05\n",
      "epoch: 31, loss: 0.07029781490564346\n",
      "epoch: 32, loss: 0.002025954658165574\n",
      "epoch: 33, loss: 0.00021317666687536985\n",
      "epoch: 34, loss: 1.1617893505899701e-05\n",
      "epoch: 35, loss: 0.0013765371404588223\n",
      "epoch: 36, loss: 0.0021975224371999502\n",
      "epoch: 37, loss: 5.387833880377002e-05\n",
      "epoch: 38, loss: 1.2268317277630558e-06\n",
      "epoch: 39, loss: 3.937027940992266e-06\n",
      "epoch: 40, loss: 2.6197727493126877e-05\n",
      "epoch: 41, loss: 0.0002025515423156321\n",
      "epoch: 42, loss: 1.2485899787861854e-05\n",
      "epoch: 43, loss: 1.5049445210024714e-05\n",
      "epoch: 44, loss: 5.263172624836443e-06\n",
      "epoch: 45, loss: 3.8053124171710806e-06\n",
      "epoch: 46, loss: 1.6565551050007343e-05\n",
      "epoch: 47, loss: 6.258304097173095e-07\n",
      "epoch: 48, loss: 7.10272445303417e-07\n",
      "epoch: 49, loss: 8.81649029338405e-08\n",
      "epoch: 50, loss: 5.383419193094596e-06\n",
      "epoch: 51, loss: 1.8513410395826213e-06\n",
      "epoch: 52, loss: 1.2417633588057697e-09\n",
      "epoch: 53, loss: 3.5141366083735193e-07\n",
      "epoch: 54, loss: 2.1109956449549827e-08\n",
      "epoch: 55, loss: 2.0861511984548997e-07\n",
      "epoch: 56, loss: 1.8005464141879202e-07\n",
      "epoch: 57, loss: 1.8129640011466108e-07\n",
      "epoch: 58, loss: 2.4835267176115394e-09\n",
      "epoch: 59, loss: 9.437381010002355e-08\n",
      "epoch: 60, loss: 6.70550832637673e-08\n",
      "epoch: 61, loss: 5.985136795061408e-07\n",
      "epoch: 62, loss: 0.0\n",
      "epoch: 63, loss: 0.0\n",
      "epoch: 64, loss: 1.415604486965094e-07\n",
      "epoch: 65, loss: 1.2417633588057697e-09\n",
      "epoch: 66, loss: 7.326384121597584e-08\n",
      "epoch: 67, loss: 8.692341957328154e-09\n",
      "epoch: 68, loss: 0.0\n",
      "epoch: 69, loss: 1.2417633588057697e-09\n",
      "epoch: 70, loss: 1.2417633588057697e-09\n",
      "epoch: 71, loss: 7.326388384853999e-08\n",
      "epoch: 72, loss: 0.0\n",
      "epoch: 73, loss: 4.967052547044659e-09\n",
      "epoch: 74, loss: 1.1175868230850483e-08\n",
      "epoch: 75, loss: 0.0\n",
      "epoch: 76, loss: 3.7252896323280993e-09\n",
      "epoch: 77, loss: 4.967052991133869e-09\n",
      "epoch: 78, loss: 1.2417633588057697e-09\n",
      "epoch: 79, loss: 0.0\n",
      "epoch: 80, loss: 2.4835267176115394e-09\n",
      "epoch: 81, loss: 0.0\n",
      "epoch: 82, loss: 0.0\n",
      "epoch: 83, loss: 0.0\n",
      "epoch: 84, loss: 0.0\n",
      "epoch: 85, loss: 0.0\n",
      "epoch: 86, loss: 0.0\n",
      "epoch: 87, loss: 0.0\n",
      "epoch: 88, loss: 0.0\n",
      "epoch: 89, loss: 0.0\n",
      "epoch: 90, loss: 0.0\n",
      "epoch: 91, loss: 0.0\n",
      "epoch: 92, loss: 0.0\n",
      "epoch: 93, loss: 0.0\n",
      "epoch: 94, loss: 0.0\n",
      "epoch: 95, loss: 0.0\n",
      "epoch: 96, loss: 0.0\n",
      "epoch: 97, loss: 0.0\n",
      "epoch: 98, loss: 0.0\n",
      "epoch: 99, loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 100\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # Forward Process\n",
    "        outputs = model(imgs)\n",
    "        loss = Loss(outputs, labels)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch: {}, loss: {}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.29\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs, labels in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_ckpt.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Load the trained model parameters\n",
    "model.load_state_dict(torch.load('model_ckpt.pt'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "opt = model(trainset[0][0].view(1,1,28,28).cuda())\n",
    "_, predicted = torch.max(opt, dim=1)\n",
    "print(predicted.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conversion\n",
    "- torch to onnx\n",
    "- onnx to engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch To ONNX Model\n",
    "- to view at netron.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (convblock1): ConvBlock(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convblock2): ConvBlock(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define model structure\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 1*1*28*28\n",
    "        self.convblock1 = ConvBlock(1, 32)\n",
    "        # 1*32*14*14\n",
    "        self.convblock2 = ConvBlock(32, 64)\n",
    "        # 1*64*7*7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = self.convblock1(img)\n",
    "        img = self.convblock2(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.fc1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.fc2(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Load the trained model parameters\n",
    "model.load_state_dict(torch.load('model_ckpt.pt'))\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()  # make model into evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make model into onnx model\n",
    "\n",
    "x = torch.rand(size=(1,1,28,28), dtype=torch.float32).cuda()\n",
    "torch.onnx.export(  # export onnx model / you can open .onnx file with netron.app\n",
    "    model,\n",
    "    x,\n",
    "    f='my_model.onnx', \n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONNX Model to Engine\n",
    "- Here is a problem, there is an error if I want to set_shape : input is static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_engine = True\n",
    "onnx_file_path = 'my_model.onnx'\n",
    "engine_file_path = 'engine.trt'\n",
    "bUseFP16Mode = True  # If this mode then only set flag\n",
    "bUseINT8Mode = False  # If this mode then need calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "\n",
    "# Create network and make it into explicit mode\n",
    "explicit_mode = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(explicit_mode)\n",
    "\n",
    "# If the network has any dynamic input tensors, this call must be made.\n",
    "profile = builder.create_optimization_profile()\n",
    "\n",
    "# Config that how to create engine by builder\n",
    "config = builder.create_builder_config()\n",
    "\n",
    "# INT8/ FP16 / FP32\n",
    "if bUseFP16Mode:\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "if bUseINT8Mode:\n",
    "    config.set_flag(trt.BuilderFlag.INT8)\n",
    "    #  config.int8_calibrator = calibrator.MyCalibrator()\n",
    "\n",
    "# Create ONNX parser\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "\n",
    "with open(onnx_file_path, 'rb') as model:\n",
    "    if not parser.parse(model.read()):\n",
    "        print('Failed\\n')\n",
    "        for error in range(parser.num_errors):\n",
    "            print(parser.get_error(error))\n",
    "        exit()\n",
    "\n",
    "# inputTensor = network.get_input(0)\n",
    "# profile.set_shape(inputTensor.name, [1,1,28,28],[1,1,28,28],[4,1,28,28])\n",
    "config.add_optimization_profile(profile)\n",
    "# network.unmark_output(network.get_output(0))\n",
    "\n",
    "engine = builder.build_serialized_network(network, config)\n",
    "if write_engine:\n",
    "    with open(engine_file_path, 'wb') as f:\n",
    "        f.write(engine)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger()\n",
    "\n",
    "with open('engine.trt', 'rb') as f:\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['input', 'output']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "nIO = engine.num_io_tensors\n",
    "lTensorName = [engine.get_tensor_name(i) for i in range(nIO)]\n",
    "nInput = [engine.get_tensor_mode(lTensorName[i]) for i in range(nIO)].count(trt.TensorIOMode.INPUT)\n",
    "\n",
    "print(nIO)\n",
    "print(lTensorName)\n",
    "print(nInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/12/2023-19:10:26] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = engine.create_execution_context()\n",
    "context.set_input_shape(lTensorName[0], [1, 1, 28, 28])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Achieved by PIL\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((28, 28)),\n",
    "     transforms.ToTensor(),]\n",
    ")\n",
    "\n",
    "def preprocess(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    tensor_image = transform(img)\n",
    "    return tensor_image.view([1, 1, 28, 28])\n",
    "\n",
    "img_in = preprocess('./data/Test/3.jpg')\n",
    "print(img_in.dtype)\n",
    "print(img_in.shape)\n",
    "img_in = img_in.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achieved by cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### buffer management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "[[[[1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         0.99215686\n",
      "    0.9882353  0.99607843 1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         0.8        0.56078434\n",
      "    0.5294118  0.5568628  0.78431374 0.99215686 1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         0.8784314  0.8980392\n",
      "    0.9137255  0.84313726 0.48235294 0.91764706 1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         0.9411765  0.5019608  0.93333334 1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    0.9764706  0.62352943 0.69411767 0.99607843 1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         0.96862745\n",
      "    0.6431373  0.6509804  0.9764706  1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         0.972549   0.63529414\n",
      "    0.69803923 0.98039216 1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         0.84705883 0.54901963\n",
      "    0.9490196  1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         0.95686275 0.63529414\n",
      "    0.5137255  0.627451   0.8117647  0.9529412  0.99607843 1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         0.99215686\n",
      "    0.9254902  0.7607843  0.5686275  0.4862745  0.61960787 0.8666667\n",
      "    0.99215686 1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         0.99607843 0.9254902  0.72156864 0.4862745\n",
      "    0.6117647  0.9607843  1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         0.9411765\n",
      "    0.47058824 0.7882353  1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         0.95686275 0.79607844 0.5372549\n",
      "    0.5254902  0.92941177 1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         0.99607843\n",
      "    0.9411765  0.80784315 0.6117647  0.46666667 0.5372549  0.78431374\n",
      "    0.96862745 1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         0.8039216  0.60784316 0.5294118\n",
      "    0.45490196 0.5254902  0.7176471  0.9019608  0.9882353  1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         0.99607843 0.73333335 0.64705884 0.80784315\n",
      "    0.93333334 0.99215686 1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]\n",
      "   [1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.         1.         1.\n",
      "    1.         1.         1.         1.        ]]]]\n",
      "output\n",
      "[[-17.616848 -11.921762 -23.449007 -10.854567 -29.237833 -20.136686\n",
      "  -10.899019 -16.378046 -25.708735 -22.592709]]\n",
      "Succeeded running model in TensorRT!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "\n",
    "bufferH = []\n",
    "bufferH.append(np.ascontiguousarray(img_in))\n",
    "for i in range(nInput, nIO):\n",
    "    bufferH.append(np.empty(context.get_tensor_shape(lTensorName[i]), dtype=trt.nptype(engine.get_tensor_dtype(lTensorName[i]))))\n",
    "bufferD = []\n",
    "for i in range(nIO):\n",
    "    bufferD.append(cudart.cudaMalloc(bufferH[i].nbytes)[1])\n",
    "\n",
    "for i in range(nInput):\n",
    "    cudart.cudaMemcpy(bufferD[i], bufferH[i].ctypes.data, bufferH[i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)\n",
    "\n",
    "for i in range(nIO):\n",
    "    context.set_tensor_address(lTensorName[i], int(bufferD[i]))\n",
    "\n",
    "context.execute_async_v3(0)\n",
    "for i in range(nInput, nIO):\n",
    "    cudart.cudaMemcpy(bufferH[i].ctypes.data, bufferD[i], bufferH[i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost)\n",
    "\n",
    "for i in range(nIO):\n",
    "    print(lTensorName[i])\n",
    "    print(bufferH[i])\n",
    "\n",
    "for b in bufferD:\n",
    "    cudart.cudaFree(b)\n",
    "\n",
    "print(\"Succeeded running model in TensorRT!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(max(bufferH[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
