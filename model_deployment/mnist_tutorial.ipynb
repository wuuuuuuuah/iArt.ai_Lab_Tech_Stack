{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment for MNIST\n",
    "- Training Process\n",
    "    - DataSet Preparation\n",
    "    - Data Preprocessing\n",
    "    - Model Construction\n",
    "    - Traning\n",
    "    - Testing\n",
    "    - Model Saving & Loading\n",
    "- Deployment Process\n",
    "    - to ONNX\n",
    "    - Inference Engine\n",
    "        - ONNX Runtime\n",
    "        - TensorRT running"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "- MNIST\n",
    "- Preprocessing -> transforms.Compose()\n",
    "- DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    ")\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\n",
    "    root = './data', \n",
    "    train = True,\n",
    "    transform = data_tf,\n",
    "    download = True\n",
    ")\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train = False,\n",
    "    transform = data_tf\n",
    ")\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    print(img.size())\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "- N = (Width - Kernel_size + 2*Padding) / Stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model structure\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 1*1*28*28\n",
    "        self.convblock1 = ConvBlock(1, 32)\n",
    "        # 1*32*14*14\n",
    "        self.convblock2 = ConvBlock(32, 64)\n",
    "        # 1*64*7*7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = self.convblock1(img)\n",
    "        img = self.convblock2(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.fc1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.fc2(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1359, -0.0311, -0.0957,  0.0146,  0.1360, -0.0667,  0.0667, -0.1169,\n",
       "          0.0029, -0.1248]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trainset[0][0].view(1,1,28,28).cuda()\n",
    "model(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "- Loss\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.11541032046079636\n",
      "epoch: 1, loss: 0.0780627653002739\n",
      "epoch: 2, loss: 0.028133006766438484\n",
      "epoch: 3, loss: 0.08547574281692505\n",
      "epoch: 4, loss: 0.013079293072223663\n",
      "epoch: 5, loss: 0.015158281661570072\n",
      "epoch: 6, loss: 0.02131212316453457\n",
      "epoch: 7, loss: 0.03608933463692665\n",
      "epoch: 8, loss: 0.008750793524086475\n",
      "epoch: 9, loss: 0.0016039339825510979\n",
      "epoch: 10, loss: 0.0023217021953314543\n",
      "epoch: 11, loss: 0.0014150800416246057\n",
      "epoch: 12, loss: 0.028946593403816223\n",
      "epoch: 13, loss: 4.979946606908925e-05\n",
      "epoch: 14, loss: 5.748984676756663e-06\n",
      "epoch: 15, loss: 0.0003072724211961031\n",
      "epoch: 16, loss: 0.007224217057228088\n",
      "epoch: 17, loss: 0.0005629609222523868\n",
      "epoch: 18, loss: 0.0013020599726587534\n",
      "epoch: 19, loss: 0.002345251850783825\n",
      "epoch: 20, loss: 0.00010087257396662608\n",
      "epoch: 21, loss: 4.92084764118772e-05\n",
      "epoch: 22, loss: 0.0004791969258803874\n",
      "epoch: 23, loss: 1.950174555531703e-05\n",
      "epoch: 24, loss: 2.3306007278733887e-05\n",
      "epoch: 25, loss: 5.02959119330626e-05\n",
      "epoch: 26, loss: 0.00027265012613497674\n",
      "epoch: 27, loss: 1.1163329872942995e-05\n",
      "epoch: 28, loss: 7.39685638109222e-05\n",
      "epoch: 29, loss: 2.298345634699217e-06\n",
      "epoch: 30, loss: 1.6170866729225963e-05\n",
      "epoch: 31, loss: 0.07029781490564346\n",
      "epoch: 32, loss: 0.002025954658165574\n",
      "epoch: 33, loss: 0.00021317666687536985\n",
      "epoch: 34, loss: 1.1617893505899701e-05\n",
      "epoch: 35, loss: 0.0013765371404588223\n",
      "epoch: 36, loss: 0.0021975224371999502\n",
      "epoch: 37, loss: 5.387833880377002e-05\n",
      "epoch: 38, loss: 1.2268317277630558e-06\n",
      "epoch: 39, loss: 3.937027940992266e-06\n",
      "epoch: 40, loss: 2.6197727493126877e-05\n",
      "epoch: 41, loss: 0.0002025515423156321\n",
      "epoch: 42, loss: 1.2485899787861854e-05\n",
      "epoch: 43, loss: 1.5049445210024714e-05\n",
      "epoch: 44, loss: 5.263172624836443e-06\n",
      "epoch: 45, loss: 3.8053124171710806e-06\n",
      "epoch: 46, loss: 1.6565551050007343e-05\n",
      "epoch: 47, loss: 6.258304097173095e-07\n",
      "epoch: 48, loss: 7.10272445303417e-07\n",
      "epoch: 49, loss: 8.81649029338405e-08\n",
      "epoch: 50, loss: 5.383419193094596e-06\n",
      "epoch: 51, loss: 1.8513410395826213e-06\n",
      "epoch: 52, loss: 1.2417633588057697e-09\n",
      "epoch: 53, loss: 3.5141366083735193e-07\n",
      "epoch: 54, loss: 2.1109956449549827e-08\n",
      "epoch: 55, loss: 2.0861511984548997e-07\n",
      "epoch: 56, loss: 1.8005464141879202e-07\n",
      "epoch: 57, loss: 1.8129640011466108e-07\n",
      "epoch: 58, loss: 2.4835267176115394e-09\n",
      "epoch: 59, loss: 9.437381010002355e-08\n",
      "epoch: 60, loss: 6.70550832637673e-08\n",
      "epoch: 61, loss: 5.985136795061408e-07\n",
      "epoch: 62, loss: 0.0\n",
      "epoch: 63, loss: 0.0\n",
      "epoch: 64, loss: 1.415604486965094e-07\n",
      "epoch: 65, loss: 1.2417633588057697e-09\n",
      "epoch: 66, loss: 7.326384121597584e-08\n",
      "epoch: 67, loss: 8.692341957328154e-09\n",
      "epoch: 68, loss: 0.0\n",
      "epoch: 69, loss: 1.2417633588057697e-09\n",
      "epoch: 70, loss: 1.2417633588057697e-09\n",
      "epoch: 71, loss: 7.326388384853999e-08\n",
      "epoch: 72, loss: 0.0\n",
      "epoch: 73, loss: 4.967052547044659e-09\n",
      "epoch: 74, loss: 1.1175868230850483e-08\n",
      "epoch: 75, loss: 0.0\n",
      "epoch: 76, loss: 3.7252896323280993e-09\n",
      "epoch: 77, loss: 4.967052991133869e-09\n",
      "epoch: 78, loss: 1.2417633588057697e-09\n",
      "epoch: 79, loss: 0.0\n",
      "epoch: 80, loss: 2.4835267176115394e-09\n",
      "epoch: 81, loss: 0.0\n",
      "epoch: 82, loss: 0.0\n",
      "epoch: 83, loss: 0.0\n",
      "epoch: 84, loss: 0.0\n",
      "epoch: 85, loss: 0.0\n",
      "epoch: 86, loss: 0.0\n",
      "epoch: 87, loss: 0.0\n",
      "epoch: 88, loss: 0.0\n",
      "epoch: 89, loss: 0.0\n",
      "epoch: 90, loss: 0.0\n",
      "epoch: 91, loss: 0.0\n",
      "epoch: 92, loss: 0.0\n",
      "epoch: 93, loss: 0.0\n",
      "epoch: 94, loss: 0.0\n",
      "epoch: 95, loss: 0.0\n",
      "epoch: 96, loss: 0.0\n",
      "epoch: 97, loss: 0.0\n",
      "epoch: 98, loss: 0.0\n",
      "epoch: 99, loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 100\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # Forward Process\n",
    "        outputs = model(imgs)\n",
    "        loss = Loss(outputs, labels)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch: {}, loss: {}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.29\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for imgs, labels in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_ckpt.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Load the trained model parameters\n",
    "model.load_state_dict(torch.load('model_ckpt.pt'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "opt = model(trainset[0][0].view(1,1,28,28).cuda())\n",
    "_, predicted = torch.max(opt, dim=1)\n",
    "print(predicted.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conversion\n",
    "- torch to onnx\n",
    "- onnx to engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch To ONNX Model\n",
    "- to view at netron.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (convblock1): ConvBlock(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convblock2): ConvBlock(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU()\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define model structure\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 1*1*28*28\n",
    "        self.convblock1 = ConvBlock(1, 32)\n",
    "        # 1*32*14*14\n",
    "        self.convblock2 = ConvBlock(32, 64)\n",
    "        # 1*64*7*7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img = self.convblock1(img)\n",
    "        img = self.convblock2(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.fc1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.fc2(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Load the trained model parameters\n",
    "model.load_state_dict(torch.load('model_ckpt.pt'))\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()  # make model into evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make model into onnx model\n",
    "\n",
    "x = torch.rand(size=(1,1,28,28), dtype=torch.float32).cuda()\n",
    "torch.onnx.export(  # export onnx model / you can open .onnx file with netron.app\n",
    "    model,\n",
    "    x,\n",
    "    f='my_model.onnx', \n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    opset_version=11\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONNX Model to Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_engine = True\n",
    "engine_file_path = 'engine.trt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-15:50:56] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "# batch_size = 8\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network(explicit_batch) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    # builder.max_batch_size = batch_size\n",
    "    config = builder.create_builder_config()\n",
    "    # config.max_workspace_size = common.GiB(2)\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "    with open('my_model.onnx', 'rb') as model:\n",
    "        parser.parse(model.read())\n",
    "    profile = builder.create_optimization_profile()\n",
    "    # profile.set_shape('input', (1, 1, 28, 28), (1, 1, 28, 28), (4, 1, 28, 28))\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    engine = builder.build_serialized_network(network, config)\n",
    "\n",
    "    if write_engine:\n",
    "        with open(engine_file_path, 'wb') as f:\n",
    "            f.write(engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-16:31:13] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger()\n",
    "\n",
    "with open('engine.trt', 'rb') as f:\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((28, 28)),\n",
    "     transforms.ToTensor(),]\n",
    ")\n",
    "\n",
    "def preprocess(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    tensor_image = transform(img)\n",
    "    return tensor_image.view([1, 1, 28, 28])\n",
    "\n",
    "img_in = preprocess('./data/Test/3.jpg')\n",
    "print(img_in.dtype)\n",
    "print(img_in.shape)\n",
    "img_in = img_in.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328195/2682600912.py:8: DeprecationWarning: Use get_tensor_name instead.\n",
      "  binding_idx = engine.get_binding_index(binding)\n",
      "/tmp/ipykernel_328195/2682600912.py:9: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  size = trt.volume(context.get_binding_shape(binding_idx))\n",
      "/tmp/ipykernel_328195/2682600912.py:10: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
      "/tmp/ipykernel_328195/2682600912.py:11: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if engine.binding_is_input(binding):\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "explicit_context_dependent failed: invalid device context - no currently active context?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m engine\u001b[39m.\u001b[39mbinding_is_input(binding):\n\u001b[1;32m     12\u001b[0m     input_buffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(img_in)\n\u001b[0;32m---> 13\u001b[0m     input_memory \u001b[39m=\u001b[39m cuda\u001b[39m.\u001b[39;49mmem_alloc(img_in\u001b[39m.\u001b[39;49mnbytes)\n\u001b[1;32m     14\u001b[0m     bindings\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39m(input_memory))\n\u001b[1;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mLogicError\u001b[0m: explicit_context_dependent failed: invalid device context - no currently active context?"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "# Memory Allocation\n",
    "inputs = []\n",
    "outputs = []\n",
    "bindings = []\n",
    "for binding in engine:\n",
    "    binding_idx = engine.get_binding_index(binding)\n",
    "    size = trt.volume(context.get_binding_shape(binding_idx))\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "    if engine.binding_is_input(binding):\n",
    "        input_buffer = np.ascontiguousarray(img_in)\n",
    "        input_memory = cuda.mem_alloc(img_in.nbytes)\n",
    "        bindings.append(int(input_memory))\n",
    "    else:\n",
    "        output_buffer = cuda.pagelocked_empty(size, dtype)\n",
    "        output_memory = cuda.mem_alloc(output_buffer.nbytes)\n",
    "        bindings.append(int(output_memory))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Engine - TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6.1\n",
      "[06/09/2023-15:05:32] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "# Test your TensorRT\n",
    "import tensorrt\n",
    "print(tensorrt.__version__)\n",
    "assert tensorrt.Builder(tensorrt.Logger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.Resize((28, 28)),\n",
    "     transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "def preprocess(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    tensor_image = transform(img)\n",
    "    return tensor_image.view(1,1,28,28).cuda()\n",
    "\n",
    "img_path = './data/Test/3.jpg'\n",
    "tensor_image = preprocess(img_path)\n",
    "\n",
    "print(tensor_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load Model to Test\n",
    "model.eval()\n",
    "opt = model(tensor_image)\n",
    "_, predicted = torch.max(opt, dim=1)\n",
    "print(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-15:06:43] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "# Conversion\n",
    "TRT_LOGGER = trt.Logger()\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1)\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "\n",
    "with open('my_model.onnx', 'rb') as model:\n",
    "    parser.parse(model.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = builder.create_builder_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12487/1880637938.py:1: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    }
   ],
   "source": [
    "engine = builder.build_engine(network, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-15:22:51] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate host and device buffers\n",
    "input_buf = cuda.mem_alloc(1*1*28*28*trt.float32.itemsize)\n",
    "output_buf = cuda.mem_alloc(1*10*trt.float32.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(input_buf, tensor_image.cpu().flatten().numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/09/2023-15:24:25] [TRT] [E] 1: [convBaseRunner.cpp::execute::295] Error Code 1: Cask (Cask convolution execution)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bindings = [int(input_buf), int(output_buf)]\n",
    "context.execute_v2(bindings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
