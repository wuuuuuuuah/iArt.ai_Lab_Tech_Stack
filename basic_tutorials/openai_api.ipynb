{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../my_key.txt') as f:\n",
    "    key_list = f.readlines()\n",
    "\n",
    "key_list = [key.strip() for key in key_list]\n",
    "\n",
    "keys = {}\n",
    "for key in key_list:\n",
    "    key = key.split(':')\n",
    "    if (key != ['']):\n",
    "        keys[key[0]] = key[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = keys['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiktoken\n",
    "- Use to count the number of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4416, 1103, 19, 5163, 220]\n"
     ]
    }
   ],
   "source": [
    "text_to_token = ' [[url4]] '\n",
    "tokens_list = encoding.encode(text_to_token)\n",
    "print(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([12805])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Original Call\n",
    "- prompt 1765 + completion 226 = \n",
    "    - 'gpt-3.5-turbo': 18s+14s+15s /3 = 16s\n",
    "    - 'text-davinci-003': above 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "openai.organization = keys['OPENAI_ORGANIZATION']\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "# openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_content = \"A tiger does not lose sleep over the opinion of sheep.\"\n",
    "text2_content = \"The tiger's strength is born from the struggle.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo\n",
    "- Without Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"You are a story teller. Make a story from two sentences.\"\"\"\n",
    "\n",
    "text = text1_content + '\\n' + text2_content\n",
    "\n",
    "usr_prompt = f\"\"\"\n",
    "Sentences: {text}\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "tur_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f'{sys_prompt}'},\n",
    "        {\"role\": 'user', 'content': f'{usr_prompt}'},\n",
    "    ],\n",
    "    temperature = 0,\n",
    ")\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The article compares two popular language models, GPT-3 and BERT, and discusses their differences and similarities, exploring their capabilities and the tools that use them. GPT-3 is an autoregressive language model developed by OpenAI, while BERT is a bidirectional transformer model developed by Google AI. The main difference between the two models lies in their architecture and training dataset size, with GPT-3 being better suited for tasks such as summarization or translation, while BERT is more beneficial for sentiment analysis or natural language understanding (NLU). However, both models have proven themselves valuable tools for performing various NLP tasks with varying degrees of accuracy.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1685508068,\n",
      "  \"id\": \"chatcmpl-7M7vwE8NQeN2sDGdZBmt35eFvgzdK\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 134,\n",
      "    \"prompt_tokens\": 1750,\n",
      "    \"total_tokens\": 1884\n",
      "  }\n",
      "}\n",
      "9.403381586074829s\n"
     ]
    }
   ],
   "source": [
    "print(str(tur_response) + '\\n' + str(stop - start) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article compares two popular language models, GPT-3 and BERT, and discusses their differences and similarities, exploring their capabilities and the tools that use them. GPT-3 is an autoregressive language model developed by OpenAI, while BERT is a bidirectional transformer model developed by Google AI. The main difference between the two models lies in their architecture and training dataset size, with GPT-3 being better suited for tasks such as summarization or translation, while BERT is more beneficial for sentiment analysis or natural language understanding (NLU). However, both models have proven themselves valuable tools for performing various NLP tasks with varying degrees of accuracy.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tur_response['choices'][0]['message']['content']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo\n",
    "- With Streaming\n",
    "    - use 'stream = True'\n",
    "    - automatically call 'await'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once\n",
      " upon a time\n",
      ", in a\n",
      " dense forest,\n",
      "k lived a\n",
      " majestic tiger.\n",
      " He was feared\n",
      " by all the\n",
      " animals in the\n",
      " forest, but\n",
      " he never cared\n",
      " about their opinions\n",
      ". He knew\n",
      " that he was\n",
      " strong and powerful\n",
      ", and his\n",
      " strength was born\n",
      " from the struggles\n",
      " he faced in\n",
      " his life.\n",
      "\n",
      "\n",
      "One day,\n",
      " a group of\n",
      " sheep came to\n",
      " the tiger and\n",
      " started mocking him\n",
      " for his stripes\n",
      " and his fer\n",
      "ocious nature.\n",
      " The tiger just\n",
      " smiled and said\n",
      ", \"A\n",
      " tiger does not\n",
      " lose sleep over\n",
      " the opinion of\n",
      " sheep.\" The\n",
      " sheep were surprised\n",
      " by the tiger\n",
      "'s response and\n",
      " realized that they\n",
      " were no match\n",
      " for his strength\n",
      " and courage.\n",
      "\n",
      "\n",
      "From that day\n",
      " on, the\n",
      " tiger became a\n",
      " legend in the\n",
      " forest, and\n",
      " all the animals\n",
      " respected him for\n",
      " his bravery and\n",
      " wisdom. He\n",
      " continued to face\n",
      " struggles and challenges\n",
      ", but he\n",
      " never lost his\n",
      " confidence and always\n",
      " emerged victorious.\n",
      "\n",
      "\n",
      "The tiger's\n",
      " story became an\n",
      " inspiration for all\n",
      " the animals in\n",
      " the forest,\n",
      " and they learned\n",
      " that true strength\n",
      " comes from within\n",
      " and is born\n",
      " from the struggles\n",
      " we face in\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = \"\"\"You are a story teller. Make a story from two sentences.\"\"\"\n",
    "\n",
    "text = text1_content + '\\n' + text2_content\n",
    "\n",
    "usr_prompt = f\"\"\"\n",
    "Sentences: {text}\n",
    "\"\"\"\n",
    "\n",
    "tur_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f'{sys_prompt}'},\n",
    "        {\"role\": 'user', 'content': f'{usr_prompt}'},\n",
    "    ],\n",
    "    temperature = 0,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "i = 0\n",
    "NUM_TOKEN_OUT = 3\n",
    "text_chunk = ''\n",
    "for chunk in tur_response:\n",
    "    try:\n",
    "        text_chunk += chunk['choices'][0]['delta']['content']\n",
    "        if (i % NUM_TOKEN_OUT == 0):\n",
    "            print(text_chunk)\n",
    "            text_chunk = ''\n",
    "        i += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"You are a story teller. Make a story from two sentences.\"\"\"\n",
    "\n",
    "text = text1_content + '\\n' + text2_content\n",
    "\n",
    "usr_prompt = f\"\"\"\n",
    "Sentences: {text}\n",
    "\"\"\"\n",
    "\n",
    "tur_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f'{sys_prompt}'},\n",
    "        {\"role\": 'user', 'content': f'{usr_prompt}'},\n",
    "    ],\n",
    "    temperature = 0,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "NUM_TOKEN_OUT = 3\n",
    "text_chunk = ''\n",
    "for chunk in tur_response:\n",
    "    try:\n",
    "        if (chunk['choices'][0]['delta']['content'] == ' there'):\n",
    "            j += 1\n",
    "        text_chunk += chunk['choices'][0]['delta']['content']\n",
    "        if (i % NUM_TOKEN_OUT == 0):\n",
    "            print(text_chunk)\n",
    "            text_chunk = ''\n",
    "        i += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text1_content + '\\n' + text2_content\n",
    "\n",
    "usr_prompt = f\"\"\"You are a story teller. Make a story from two sentences.\n",
    "Sentences: {text}\n",
    "Story:\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "da_response = openai.Completion.create(\n",
    "    engine = 'text-davinci-003',\n",
    "    prompt = usr_prompt,\n",
    "    max_tokens = 300\n",
    ")\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7M6v1z4mPhssrfNtkAWmzPXFAdDk4 at 0x7f85c38ca150> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"GPT-3 and BERT are two well-known language models used in natural language processing (NLP) applications. GPT-3 is an autoregressive model trained on 45TB of data while BERT is bidirectional and trained on 3TB of data. They have significant differences in architecture and data sizes, but both are Transformer-based and can be used for similar tasks such as question answering, summarization, and translation. GPT-3 typically outperforms BERT in tasks that require more data, while BERT is better for sentiment analysis and natural language understanding. GPT-2 models can be used to generate data from prompts, while BERT can be used for zero- and few-shot learning with the PET method. [from url1 and url2]\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1685504167,\n",
       "  \"id\": \"cmpl-7M6v1z4mPhssrfNtkAWmzPXFAdDk4\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 161,\n",
       "    \"prompt_tokens\": 1832,\n",
       "    \"total_tokens\": 1993\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "da_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT-3 and BERT are two well-known language models used in natural language processing (NLP) applications. GPT-3 is an autoregressive model trained on 45TB of data while BERT is bidirectional and trained on 3TB of data. They have significant differences in architecture and data sizes, but both are Transformer-based and can be used for similar tasks such as question answering, summarization, and translation. GPT-3 typically outperforms BERT in tasks that require more data, while BERT is better for sentiment analysis and natural language understanding. GPT-2 models can be used to generate data from prompts, while BERT can be used for zero- and few-shot learning with the PET method. [from url1 and url2]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "da_response['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SemanticKernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
